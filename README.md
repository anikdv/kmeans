# Пример реализации кластеризации с использованием алгоритма k-means

### Формальное описание задачи кластеризации

Дано множество объектов данных I, каждый из которых представлен набором атрибутов. Требуется построить множество кластеров C и отображение F множества I на множество C, т.е. F : I > C. Отображение F задаёт модель данных, являющуюся решением задачи. Качество решения задачи определяется количеством верно классифицированных объектов данных. 

Множество I определим следующим образом:

![Alt text](pictures/objects_set_I.svg?raw=true "I_set"),

где _i<sub>j</sub>_- исследуемый объект.

Каждый из объектов характеризуется набором параметров (m-мерным вектором):

![Alt text](pictures/object_params.svg?raw=true "object_params").

Каждая переменная может принимать значения из некоторого множества:

![Alt text](pictures/available_values.svg?raw=true "available_values").

Задача кластеризации состоит в построении множества:

![Alt text](pictures/cluster_definition.svg?raw=true "cluster_definition"),

Здесь _C_ - кластер, содержащий похожие друг на друга объекты из множества I:

![Alt text](pictures/cluster_restriction.svg?raw=true "cluster_restriction"),

где _&rho;(i<sub>j</sub>, i<sub>l</sub>)_ - функция расстояния между объектами, _&sigma;_ - минимально допустимое расстояние между объектами в кластере.

### Определение расстояния между объектами

В простейшем случае для определения расстояния между объектами _i_ и _i'_ можно воспользоваться метрикой, называемой "Манхэттенским расстоянием", имеющим вид:

![Alt text](pictures/distance_1.svg?raw=true "distance_1").

Более точную оценку можно получить, используя Евклидово расстояние, формула которого представлена ниже:

![Alt text](pictures/distance_2.svg?raw=true "distance_2").

Приведенные метрики имеют явную связь и легко могут быть расширены до _p_-мерного пространства (метрика Минковского):

![Alt text](pictures/distance_p.svg?raw=true "distance_p").

На практике наиболее часто применяется Евклидово расстояние.

#### Определение расстояния в условиях высокой дисперсии характеристик

В некоторых случаях кластеризация на основе многомерных векторов требует проведения предварительной нормализации либо этих векторов

![Alt text](pictures/object_params.svg?raw=true "object_params"),

либо значений этих векторов

![Alt text](pictures/available_values.svg?raw=true "available_values").

Нормализацией вектора называют операцию приведения его к единичной длинне. В Евклидовом пространстве для осуществления нормализации необходимо каждую компоненту вектора (в предыдущей формуле - _x<sub>h</sub>_) поделить на длину этого вектора. Длина вектора определяется как корень из скалярного произведения этого вектора на самого себя. Подробнее с операцией скалярного произведения можно ознакомиться [здесь](http://www.math.mrsu.ru/text/courses/method/dlina_vectora__ugol_megdu_n-mernimi_vectorami.htm).

### Метод k-средних

С описанием алгоритма также можно ознакомиться [здесь](https://studfile.net/preview/6172591/page:24/).

#### Задача

Определить реальную границу времен года. 

#### Формальное описание задачи

1. Множество элементов _I_ получается из внешних источников. Для решения данной задачи сведения могут быть получены [отсюда](https://rp5.ru/%D0%90%D1%80%D1%85%D0%B8%D0%B2_%D0%BF%D0%BE%D0%B3%D0%BE%D0%B4%D1%8B_%D0%B2_%D0%A0%D1%8F%D0%B7%D0%B0%D0%BD%D0%B8).
2. Определение мерности множества. Для решения задачи необходимо анализировать температуру. Т.о. мерность _m_ = 1, _x<sub>1</sub>_ - температура.
3. Выполнение нормализации не требуется, так как мерность равна 1.
4. Оценка расстояния выполняется с помощью Евклидовоц метрики, _lim &sigma; &rarr; 0_.

#### Определение начальных условий

1. Выбирается количество кластеров k. Количество центров кластеризации определяется предметной областью и спецификой задачи. Например, для определения реальных границ времен года можно выбирать k = 2 (если интересует летний и зимний период), либо k = 4 (если интересуют все 4 времени года).
Для описанного случая: ![Alt text](pictures/example_cluster.svg?raw=true "available_values")
2. Для каждого кластера выбирается центр кластеризации так, чтобы он находился максимально близко (по мнению эксперта - выбирающего) к результирующему положению центра кластеризации. Например, при выделении границ времен года центром кластеризации будет являться центральная точка каждого из времен года, т.е. значение температуры 15-го января для зимы, 15-го июля для лета и т.п. Для указанного примера центром кластеризации _q<sub>1</sub>_ для кластера _c<sub>1</sub>_ является среднее значение температуры за 15 января, а центром кластеризации _q<sub>2</sub>_ для кластера _c<sub>2</sub>_ является среднее значение температуры за 15 июля.

#### Итеративное определение кластеров

Кластеры самоболансируются за счет итеративного выполнения следующих двух шагов.

1. Точка _i<sub>j</sub>_ относится к _c<sub>g</sub>_, тогда и только тогда, когда расстояние от нее до цетра масс _q<sub>g</sub>_ минимальное (в сравнении с расстояниями до других цетров масс):

![Alt text](pictures/first_step.svg?raw=true "first_step").

В результате разбиения в кластере _c<sub>g</sub>_ будет _s<sub>g</sub>_ элементов.

2. Для каждого кластера, полученного на первом шаге, определяется его центр масс:

![Alt text](pictures/second_step_cluster_center.svg?raw=true "second_step_cluster_center"),

 где _u<sub>gh</sub>_ - коэффициент принадлежности, определяемый по формуле:
 
 ![Alt text](pictures/second_step_cluster_similarity.svg?raw=true "second_step_cluster_center"),
 
 где в свою очередь _q'<sub>h</sub>_ - центр масс кластера на предыдущем шаге, _D_ - коэффициент неопределенности.
 
 _**Коэффициент неопределенности**_ задается на начальном этапе и позволяет вместо погрешности _&sigma;_ задать точность определения границ кластера.
 
 #### Остановка алгоритма
 
 Выполнение алгоритма останавливается тогда, когда центры кластеров перестают меняться больше чем на некоторую _&Delta;&rho;_, либо по достижении лимита итераций.
 
 Пример реализации алгоритма на python можно посмотреть [здесь](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html).
